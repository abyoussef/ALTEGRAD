{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re \n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_data = 'data/'\n",
    "\n",
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "training_info = pd.read_csv(path_to_data + 'training_info.csv', sep=',', header=0)\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)\n",
    "test_info = pd.read_csv(path_to_data + 'test_info.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training      : columns ['sender' 'mids'] - length 125\n",
      "training_info : columns ['mid' 'date' 'body' 'recipients'] - length 43613\n",
      "test          : columns ['sender' 'mids'] - length 125\n",
      "test_info     : columns ['mid' 'date' 'body'] - length 2362\n"
     ]
    }
   ],
   "source": [
    "print \"training      : columns\", training.columns.values, \"- length\", len(training)\n",
    "print \"training_info : columns\", training_info.columns.values, \"- length\", len(training_info)\n",
    "print \"test          : columns\", test.columns.values, \"- length\", len(test)\n",
    "print \"test_info     : columns\", test_info.columns.values, \"- length\", len(test_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some handy structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert training set to dictionary\n",
    "emails_ids_per_sender = {}\n",
    "for index, series in training.iterrows():\n",
    "    row = series.tolist()\n",
    "    sender = row[0]\n",
    "    ids = row[1:][0].split(' ')\n",
    "    emails_ids_per_sender[sender] = ids\n",
    "\n",
    "# save all unique sender names\n",
    "all_senders = emails_ids_per_sender.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "# create address book with frequency information for each user\n",
    "address_books = {}\n",
    "i = 0\n",
    "for sender, ids in emails_ids_per_sender.iteritems():\n",
    "    recs_temp = []\n",
    "    for my_id in ids:\n",
    "        recipients = training_info[training_info['mid'] == int(my_id)]['recipients'].tolist()\n",
    "        recipients = recipients[0].split(' ')\n",
    "        # keep only legitimate email addresses\n",
    "        recipients = [rec for rec in recipients if '@' in rec]\n",
    "        recs_temp.append(recipients)\n",
    "    # flatten\n",
    "    recs_temp = [elt for sublist in recs_temp for elt in sublist]\n",
    "    # compute recipient counts\n",
    "    rec_occ = dict(Counter(recs_temp))\n",
    "    # order by frequency\n",
    "    sorted_rec_occ = sorted(rec_occ.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    # save\n",
    "    address_books[sender] = sorted_rec_occ\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique recipients : 9779\n",
      "number of unique senders : 125\n",
      "number of senders that are receivers : 121\n"
     ]
    }
   ],
   "source": [
    "# save all unique recipient names\n",
    "all_recs = list(set([elt[0] for sublist in address_books.values() for elt in sublist]))\n",
    "print \"number of unique recipients :\", len(all_recs)\n",
    "print \"number of unique senders :\", len(all_senders)\n",
    "print 'number of senders that are receivers :',len([elt for elt in all_senders if elt in all_recs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique usernames : 9783\n"
     ]
    }
   ],
   "source": [
    "# save all unique user names\n",
    "all_users = []\n",
    "all_users.extend(all_senders)\n",
    "all_users.extend(all_recs)\n",
    "all_users = list(set(all_users))\n",
    "\n",
    "print \"number of unique usernames :\", len(all_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert training set to dictionary\n",
    "emails_ids_per_sender_test = {}\n",
    "for index, series in test.iterrows():\n",
    "    row = series.tolist()\n",
    "    sender = row[0]\n",
    "    ids = row[1:][0].split(' ')\n",
    "    emails_ids_per_sender_test[sender] = ids\n",
    "\n",
    "# save all unique sender names\n",
    "all_senders_test = emails_ids_per_sender_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_senders)==set(all_senders_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of mails sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training['n_mails_sent'] = training['mids'].apply(lambda s : len(s.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     125.000000\n",
       "mean      348.904000\n",
       "std       515.821916\n",
       "min        67.000000\n",
       "25%       111.000000\n",
       "50%       168.000000\n",
       "75%       390.000000\n",
       "max      4350.000000\n",
       "Name: n_mails_sent, dtype: float64"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['n_mails_sent'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2001-11-02 05:25:29', '2002-06-24 13:15:28')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(test_info['date']),max(test_info['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0001-08-26 22:16:36', '2001-11-01 19:12:34')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(training_info['date']),max(training_info['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mails length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_info['n_words']=training_info['body'].apply(lambda x : len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43613.000000\n",
       "mean       204.850366\n",
       "std        621.085870\n",
       "min          1.000000\n",
       "25%         24.000000\n",
       "50%         70.000000\n",
       "75%        184.000000\n",
       "max      11062.000000\n",
       "Name: n_words, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info['n_words'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section aims at cleaning every email body :\n",
    "- remove stopwords\n",
    "- keep only nouns and adjectives\n",
    "- stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text_simple(text, remove_stopwords=True, pos_filtering=True, stemming=True):\n",
    "    \n",
    "    punct = string.punctuation.replace('-', '')\n",
    "    \n",
    "    # replace tabs with white spaces\n",
    "    text = text.replace('\\t',' ')\n",
    "    # convert to lower case\n",
    "    text = text.lower()\n",
    "    # remove punctuation (preserving intra-word dashes)\n",
    "    text = ''.join(l for l in text if l not in punct)\n",
    "    # strip extra white space\n",
    "    text = re.sub(' +',' ',text)\n",
    "    # strip leading and trailing white space\n",
    "    text = text.strip()\n",
    "    \n",
    "    \n",
    "    if(text.isspace() or len(text)==0):\n",
    "        return []\n",
    "    \n",
    "    # tokenize (split based on whitespace)\n",
    "    tokens = text.split(' ')\n",
    "    \n",
    "    if pos_filtering == True:\n",
    "        # apply POS-tagging\n",
    "        tagged_tokens = pos_tag(tokens)\n",
    "        # retain only nouns and adjectives\n",
    "        tokens_keep = []\n",
    "        for i in range(len(tagged_tokens)):\n",
    "            item = tagged_tokens[i]\n",
    "            if (\n",
    "            item[1] == 'NN' or #noun\n",
    "            item[1] == 'NNS' or #noun plural\n",
    "            item[1] == 'NNP' or #proper noun\n",
    "            item[1] == 'NNPS' or #proper noun plural\n",
    "            item[1] == 'JJ' or #adjective\n",
    "            item[1] == 'JJS' or #adjective plural\n",
    "            item[1] == 'JJR' #?\n",
    "            ):\n",
    "                tokens_keep.append(item[0])\n",
    "        tokens = tokens_keep\n",
    "    if remove_stopwords:\n",
    "        stpwds = stopwords.words('english')\n",
    "        # remove stopwords\n",
    "        tokens = [token for token in tokens if token not in stpwds]\n",
    "    if stemming:\n",
    "        stemmer = nltk.stem.PorterStemmer()\n",
    "        # apply Porter's stemmer\n",
    "        tokens_stemmed = list()\n",
    "        for token in tokens:\n",
    "            if token=='oed' or token =='aed':\n",
    "                continue\n",
    "            tokens_stemmed.append(stemmer.stem(token))\n",
    "        tokens = tokens_stemmed\n",
    "\n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_info['body_cleaned']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#takes approximately 25min...\n",
    "i = 0\n",
    "t0=time.clock()\n",
    "for doc in training_info['body']:\n",
    "    training_info.loc[i,'body_cleaned'] = ' '.join(clean_text_simple(doc))\n",
    "    if i%1000==0:\n",
    "        print i, 'elapsed : ',time.clock()-t0\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_info['body_cleaned']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "t0=time.clock()\n",
    "for doc in test_info['body']:\n",
    "    test_info.loc[i,'body_cleaned'] = ' '.join(clean_text_simple(doc))\n",
    "    if i%1000==0:\n",
    "        print i, 'elapsed : ',time.clock()-t0\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save to avoid preprocessing again\n",
    "test_info[['mid','date','body_cleaned']].to_csv(path_to_data+'test_info_cleaned.csv')\n",
    "training_info[['mid','date','body_cleaned','recipients']].to_csv(path_to_data+'training_info_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Build TF-IDF features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Compute TF-IDF feature vectors from both train and test mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_info_cleaned = pd.read_csv(path_to_data+'test_info_cleaned.csv',index_col=0)\n",
    "test_info_cleaned['body_cleaned'] = test_info_cleaned['body_cleaned'].replace(np.nan,'')\n",
    "\n",
    "training_info_cleaned = pd.read_csv(path_to_data+'training_info_cleaned.csv',index_col=0)\n",
    "training_info_cleaned['body_cleaned'] = training_info_cleaned['body_cleaned'].replace(np.nan,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# put all mails from train and test in one array\n",
    "all_mails = pd.concat((test_info_cleaned['body_cleaned'],training_info_cleaned['body_cleaned'])).values\n",
    "\n",
    "stpwds = stopwords.words('english')\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words = stpwds)\n",
    "\n",
    "doc_term_matrix = tfidf_vectorizer.fit_transform(all_mails)\n",
    "doc_term_train = doc_term_matrix[range(len(training_info_cleaned)),:]\n",
    "doc_term_test = doc_term_matrix[range(len(training_info_cleaned),len(training_info_cleaned)+len(test_info_cleaned)),:]\n",
    "\n",
    "# sanity check\n",
    "print doc_term_test.shape[0]==len(test_info_cleaned)\n",
    "print doc_term_train.shape[0]==len(training_info_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For each `mail_pred` that has to be predicted :\n",
    "   - Get sender and feature vector \n",
    "   - For each `mail_train` in training that was sent by sender :\n",
    "       - Compute the similarity `sim` with `mail_pred`\n",
    "       - For each recipient of `mail_train` :\n",
    "           - add 1 to `score_freq`\n",
    "           - add `sim` to `score_sim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "# will contain email ids, predictions for tf-idf prediction\n",
    "predictions_per_sender = {}\n",
    "\n",
    "# number of recipients to predict\n",
    "k = 10\n",
    "\n",
    "scores_freq = {}\n",
    "scores_sim = {}\n",
    "for index, row in test.iterrows():\n",
    "    \n",
    "    print index\n",
    "    sender = row.tolist()[0]\n",
    "    predictions = []\n",
    "    \n",
    "    # the possible recipients considered are the ones already in address book\n",
    "    possible_recipients = [elt[0] for elt in address_books[sender]]\n",
    "    \n",
    "    # get IDs of the emails for which recipient prediction is needed\n",
    "    ids_predict = row.tolist()[1].split(' ')\n",
    "    ids_predict = [int(my_id) for my_id in ids_predict]\n",
    "    \n",
    "    for id_pred in ids_predict :\n",
    "        \n",
    "        # initialize the scores for all possible recipients to zero\n",
    "        scores_freq[id_pred]={}\n",
    "        scores_sim[id_pred]={}\n",
    "        for rec in possible_recipients:\n",
    "            scores_freq[id_pred][rec]=0\n",
    "            scores_sim[id_pred][rec]=0\n",
    "        \n",
    "        #get the feature vector corresponding to the email to predict\n",
    "        row_pred = test_info.loc[test_info['mid']==int(id_pred)].index.tolist()[0]\n",
    "        vect_pred = doc_term_test[row_pred,:].todense().tolist()[0]\n",
    "        \n",
    "        #get the ids of mails in training sent by sender\n",
    "        ids_train_sender = training.loc[training['sender']==sender,'mids'].split(' ')\n",
    "        \n",
    "        #for each one, compute similarity, and increase score of all recipients\n",
    "        for id_train in ids_train_sender:\n",
    "            \n",
    "            #get the feature vector corresponding to train email\n",
    "            row_train = training_info.loc[training_info['mid']==int(id_train)].index.tolist()[0]\n",
    "            vect_train = doc_term_train[row_train,:].todense().tolist()[0]\n",
    "            \n",
    "            #compute similarity measure (vectors are already normalized)\n",
    "            sim = np.dot(vect_pred,vect_train)\n",
    "                \n",
    "            #increase the scores of recipients of the email\n",
    "            recipients = training_info[training_info['mid'] == int(id_train)]['recipients'].tolist()\n",
    "            recipients = recipients[0].split(' ')\n",
    "            recipients = [rec for rec in recipients if '@' in rec]\n",
    "            \n",
    "            for rec in recipients:\n",
    "                scores_freq[id_pred][rec]=scores[id_pred][rec]+1\n",
    "                scores_sim[id_pred][rec]=scores_sim[id_pred][rec]+sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>mids</th>\n",
       "      <th>n_mails_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>158713 158697 200301 158679 278595 298162 2002...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amr.ibrahim@enron.com</td>\n",
       "      <td>215241 3437 215640 3506 191790 3517 3520 3562 ...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrea.ring@enron.com</td>\n",
       "      <td>270705 270706 270707 270708 270709 270710 2707...</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sylvia.hu@enron.com</td>\n",
       "      <td>111444 111422 183084 111412 111347 110883 1105...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.platter@enron.com</td>\n",
       "      <td>327074 327384 327385 264443 274124 274125 2741...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>richard.shapiro@enron.com</td>\n",
       "      <td>119822 125344 120633 323342 323343 119762 1203...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>megan.parker@enron.com</td>\n",
       "      <td>361536 361285 358251 358253 358254 358255 3582...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>david.forster@enron.com</td>\n",
       "      <td>17976 17969 17967 17966 18142 17965 17955 1795...</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mike.maggi@enron.com</td>\n",
       "      <td>330758 330578 287305 287306 287307 287460 2874...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>justin.rostant@enron.com</td>\n",
       "      <td>396265 10683 252783 252782 10631 156898 252121...</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>marcus.nettelton@enron.com</td>\n",
       "      <td>11326 20711 11307 20694 185082 174587 10971 10...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kathleen.carnahan@enron.com</td>\n",
       "      <td>150702 145547 145544 150900 150574 150695 1440...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>grace.rodriguez@enron.com</td>\n",
       "      <td>326920 326971 326979 327202 327262 327458 2612...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hunter.s.shively@enron.com</td>\n",
       "      <td>390654 390655 390656 390657 390658 390659 3906...</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sandra.f.brawner@enron.com</td>\n",
       "      <td>365751 365752 365753 365754 365755 365756 3657...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>l..nicolay@enron.com</td>\n",
       "      <td>51054 126764 126787 126794 126790 58524 128394...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mark.whitt@enron.com</td>\n",
       "      <td>240318 248303 248304 240207 240113 240063 2400...</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>james.derrick@enron.com</td>\n",
       "      <td>234041 396250 234040 234038 234039 234036 2340...</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>darrell.schoolcraft@enron.com</td>\n",
       "      <td>197348 197201 1083 197837 59725 59726 59727 59...</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>l..denton@enron.com</td>\n",
       "      <td>76579 380897 76580 380896 76581 380895 76584 3...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cheryl.johnson@enron.com</td>\n",
       "      <td>110340 110209 110097 362561 110091 362559 1100...</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>scott.neal@enron.com</td>\n",
       "      <td>186720 347865 344058 336688 276109 276110 2761...</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chris.germany@enron.com</td>\n",
       "      <td>337399 337400 337401 337402 337403 337404 3374...</td>\n",
       "      <td>2473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>eric.bass@enron.com</td>\n",
       "      <td>383592 383593 383594 383595 383596 383597 3835...</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>larry.f.campbell@enron.com</td>\n",
       "      <td>90523 89475 89618 89474 90512 89473 89615 8947...</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lynn.blair@enron.com</td>\n",
       "      <td>115686 243012 41533 41534 41535 41536 41537 41...</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nancy.sellers@robertmondavi.com</td>\n",
       "      <td>212895 212897 212898 212899 212900 212912 2129...</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>harry.kingerski@enron.com</td>\n",
       "      <td>220739 220454 220456 120560 125309 120540 1253...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>m..forney@enron.com</td>\n",
       "      <td>326889 326893 326902 326904 326907 326909 3269...</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>stacey.w.white@enron.com</td>\n",
       "      <td>369537 369538 369709 369539 369885 369540 3664...</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>chris.dorland@enron.com</td>\n",
       "      <td>362747 362748 362749 362750 362751 362752 3627...</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ginger.dernehl@enron.com</td>\n",
       "      <td>220398 232649 220399 232654 220745 220746 2207...</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>cindy.stark@enron.com</td>\n",
       "      <td>69357 396218 188537 396062 188528 176052 17605...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>david.portz@enron.com</td>\n",
       "      <td>55603 184647 55630 11682 20968 11672 11606 115...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tanya.rohauer@enron.com</td>\n",
       "      <td>186767 12249 111270 111271 184621 111144 11107...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>stephanie.sever@enron.com</td>\n",
       "      <td>111049 110804 106263 110564 106270 81232 11030...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>sally.beck@enron.com</td>\n",
       "      <td>368551 368552 368553 368554 368555 368556 3685...</td>\n",
       "      <td>1426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>keegan.farrell@enron.com</td>\n",
       "      <td>108457 108448 108421 108297 10079 108187 23868...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>kenneth.thibodeaux@enron.com</td>\n",
       "      <td>369844 376762 376765 376767 376988 376990 2975...</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>christian.yoder@enron.com</td>\n",
       "      <td>7830 7829 7828 7827 7823 34070 7826 12399 7825...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>brian.redmond@enron.com</td>\n",
       "      <td>372661 248163 395946 174517 32250 34542 35328 ...</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>russell.diamond@enron.com</td>\n",
       "      <td>186624 111436 111437 111439 184571 111389 1113...</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>john.lavorato@enron.com</td>\n",
       "      <td>153919 153920 153911 153912 153913 153914 1539...</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ben.jacoby@enron.com</td>\n",
       "      <td>125382 65581 65605 65609 68669 135274 145089 1...</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>britt.davis@enron.com</td>\n",
       "      <td>34221 34214 34212 34213 34151 34209 34210 3421...</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>holly.keiser@enron.com</td>\n",
       "      <td>238330 238364 108509 108449 108401 183346 2385...</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>michael.tribolet@enron.com</td>\n",
       "      <td>300205 324463 300220 324465 378712 369903 3787...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>errol.mclaughlin@enron.com</td>\n",
       "      <td>281864 281863 281861 281862 281860 281859 2818...</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>heather.dunton@enron.com</td>\n",
       "      <td>66 268157 268159 280294 292260 268176 268210 2...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>christina.valdez@enron.com</td>\n",
       "      <td>378257 378259 378262 378263 378264 378265 3782...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>jennifer.thome@enron.com</td>\n",
       "      <td>215781 215986 216067 216089 216096 216131 2162...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>jason.wolfe@enron.com</td>\n",
       "      <td>159650 159649 159648 159647 159644 159645 1596...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>tim.belden@enron.com</td>\n",
       "      <td>55595 34069 34071 34077 34079 34081 120326 127...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>mark.greenberg@enron.com</td>\n",
       "      <td>11082 20510 11043 20477 10807 171754 174506 32...</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>fletcher.j.sturm@enron.com</td>\n",
       "      <td>265972 265973 265974 265975 265976 265977 2659...</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>c..giron@enron.com</td>\n",
       "      <td>333191 333192 333193 333194 333195 333196 3331...</td>\n",
       "      <td>927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>barry.tycholiz@enron.com</td>\n",
       "      <td>266107 248346 248348 248343 248345 248341 8282...</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>amy.fitzpatrick@enron.com</td>\n",
       "      <td>322816 179 326870 326874 326878 326879 261019 ...</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>c..williams@enron.com</td>\n",
       "      <td>232816 232807 33953 33945 33951 33937 33922 33...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>47361 47362 47363 45909 82030 45893 172644 172...</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                sender  \\\n",
       "0              karen.buckley@enron.com   \n",
       "1                amr.ibrahim@enron.com   \n",
       "2                andrea.ring@enron.com   \n",
       "3                  sylvia.hu@enron.com   \n",
       "4            phillip.platter@enron.com   \n",
       "5            richard.shapiro@enron.com   \n",
       "6               megan.parker@enron.com   \n",
       "7              david.forster@enron.com   \n",
       "8                 mike.maggi@enron.com   \n",
       "9             justin.rostant@enron.com   \n",
       "10          marcus.nettelton@enron.com   \n",
       "11         kathleen.carnahan@enron.com   \n",
       "12           grace.rodriguez@enron.com   \n",
       "13          hunter.s.shively@enron.com   \n",
       "14          sandra.f.brawner@enron.com   \n",
       "15                l..nicolay@enron.com   \n",
       "16                mark.whitt@enron.com   \n",
       "17             james.derrick@enron.com   \n",
       "18       darrell.schoolcraft@enron.com   \n",
       "19                 l..denton@enron.com   \n",
       "20            cheryl.johnson@enron.com   \n",
       "21                scott.neal@enron.com   \n",
       "22             chris.germany@enron.com   \n",
       "23                 eric.bass@enron.com   \n",
       "24          larry.f.campbell@enron.com   \n",
       "25                lynn.blair@enron.com   \n",
       "26     nancy.sellers@robertmondavi.com   \n",
       "27           harry.kingerski@enron.com   \n",
       "28                 m..forney@enron.com   \n",
       "29            stacey.w.white@enron.com   \n",
       "..                                 ...   \n",
       "95             chris.dorland@enron.com   \n",
       "96            ginger.dernehl@enron.com   \n",
       "97               cindy.stark@enron.com   \n",
       "98               david.portz@enron.com   \n",
       "99             tanya.rohauer@enron.com   \n",
       "100          stephanie.sever@enron.com   \n",
       "101               sally.beck@enron.com   \n",
       "102           keegan.farrell@enron.com   \n",
       "103       kenneth.thibodeaux@enron.com   \n",
       "104          christian.yoder@enron.com   \n",
       "105            brian.redmond@enron.com   \n",
       "106          russell.diamond@enron.com   \n",
       "107            john.lavorato@enron.com   \n",
       "108               ben.jacoby@enron.com   \n",
       "109              britt.davis@enron.com   \n",
       "110             holly.keiser@enron.com   \n",
       "111         michael.tribolet@enron.com   \n",
       "112         errol.mclaughlin@enron.com   \n",
       "113           heather.dunton@enron.com   \n",
       "114         christina.valdez@enron.com   \n",
       "115           jennifer.thome@enron.com   \n",
       "116              jason.wolfe@enron.com   \n",
       "117               tim.belden@enron.com   \n",
       "118           mark.greenberg@enron.com   \n",
       "119         fletcher.j.sturm@enron.com   \n",
       "120                 c..giron@enron.com   \n",
       "121           barry.tycholiz@enron.com   \n",
       "122          amy.fitzpatrick@enron.com   \n",
       "123              c..williams@enron.com   \n",
       "124  enron_update@concureworkplace.com   \n",
       "\n",
       "                                                  mids  n_mails_sent  \n",
       "0    158713 158697 200301 158679 278595 298162 2002...           156  \n",
       "1    215241 3437 215640 3506 191790 3517 3520 3562 ...            87  \n",
       "2    270705 270706 270707 270708 270709 270710 2707...           124  \n",
       "3    111444 111422 183084 111412 111347 110883 1105...           116  \n",
       "4    327074 327384 327385 264443 274124 274125 2741...            83  \n",
       "5    119822 125344 120633 323342 323343 119762 1203...           519  \n",
       "6    361536 361285 358251 358253 358254 358255 3582...           109  \n",
       "7    17976 17969 17967 17966 18142 17965 17955 1795...           345  \n",
       "8    330758 330578 287305 287306 287307 287460 2874...            84  \n",
       "9    396265 10683 252783 252782 10631 156898 252121...           106  \n",
       "10   11326 20711 11307 20694 185082 174587 10971 10...           140  \n",
       "11   150702 145547 145544 150900 150574 150695 1440...            70  \n",
       "12   326920 326971 326979 327202 327262 327458 2612...            97  \n",
       "13   390654 390655 390656 390657 390658 390659 3906...           405  \n",
       "14   365751 365752 365753 365754 365755 365756 3657...           187  \n",
       "15   51054 126764 126787 126794 126790 58524 128394...           104  \n",
       "16   240318 248303 248304 240207 240113 240063 2400...           283  \n",
       "17   234041 396250 234040 234038 234039 234036 2340...           606  \n",
       "18   197348 197201 1083 197837 59725 59726 59727 59...           350  \n",
       "19   76579 380897 76580 380896 76581 380895 76584 3...           101  \n",
       "20   110340 110209 110097 362561 110091 362559 1100...           169  \n",
       "21   186720 347865 344058 336688 276109 276110 2761...           523  \n",
       "22   337399 337400 337401 337402 337403 337404 3374...          2473  \n",
       "23   383592 383593 383594 383595 383596 383597 3835...          1458  \n",
       "24   90523 89475 89618 89474 90512 89473 89615 8947...           522  \n",
       "25   115686 243012 41533 41534 41535 41536 41537 41...           756  \n",
       "26   212895 212897 212898 212899 212900 212912 2129...           167  \n",
       "27   220739 220454 220456 120560 125309 120540 1253...           109  \n",
       "28   326889 326893 326902 326904 326907 326909 3269...           444  \n",
       "29   369537 369538 369709 369539 369885 369540 3664...           526  \n",
       "..                                                 ...           ...  \n",
       "95   362747 362748 362749 362750 362751 362752 3627...           819  \n",
       "96   220398 232649 220399 232654 220745 220746 2207...           434  \n",
       "97   69357 396218 188537 396062 188528 176052 17605...            90  \n",
       "98   55603 184647 55630 11682 20968 11672 11606 115...            97  \n",
       "99   186767 12249 111270 111271 184621 111144 11107...           155  \n",
       "100  111049 110804 106263 110564 106270 81232 11030...           118  \n",
       "101  368551 368552 368553 368554 368555 368556 3685...          1426  \n",
       "102  108457 108448 108421 108297 10079 108187 23868...           128  \n",
       "103  369844 376762 376765 376767 376988 376990 2975...           162  \n",
       "104  7830 7829 7828 7827 7823 34070 7826 12399 7825...            96  \n",
       "105  372661 248163 395946 174517 32250 34542 35328 ...           121  \n",
       "106  186624 111436 111437 111439 184571 111389 1113...           143  \n",
       "107  153919 153920 153911 153912 153913 153914 1539...          1009  \n",
       "108  125382 65581 65605 65609 68669 135274 145089 1...           207  \n",
       "109  34221 34214 34212 34213 34151 34209 34210 3421...           112  \n",
       "110  238330 238364 108509 108449 108401 183346 2385...           152  \n",
       "111  300205 324463 300220 324465 378712 369903 3787...           177  \n",
       "112  281864 281863 281861 281862 281860 281859 2818...           394  \n",
       "113  66 268157 268159 280294 292260 268176 268210 2...            75  \n",
       "114  378257 378259 378262 378263 378264 378265 3782...            81  \n",
       "115  215781 215986 216067 216089 216096 216131 2162...            98  \n",
       "116  159650 159649 159648 159647 159644 159645 1596...            69  \n",
       "117  55595 34069 34071 34077 34079 34081 120326 127...           177  \n",
       "118  11082 20510 11043 20477 10807 171754 174506 32...           347  \n",
       "119  265972 265973 265974 265975 265976 265977 2659...           213  \n",
       "120  333191 333192 333193 333194 333195 333196 3331...           927  \n",
       "121  266107 248346 248348 248343 248345 248341 8282...           402  \n",
       "122  322816 179 326870 326874 326878 326879 261019 ...           134  \n",
       "123  232816 232807 33953 33945 33951 33937 33922 33...            77  \n",
       "124  47361 47362 47363 45909 82030 45893 172644 172...           334  \n",
       "\n",
       "[125 rows x 3 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "id_to_pred = test_info['mid'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sum_freq = 0\n",
    "sum_sim = 0\n",
    "count = 0\n",
    "\n",
    "for id_pred in id_to_pred:\n",
    "    for rec, score_sum in scores_freq[id_pred].iteritems():\n",
    "        sum_freq = sum_freq + scores_freq[id_pred][rec]\n",
    "        sum_sim = sum_sim + scores_sim[id_pred][rec]\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save the scores\n",
    "import json\n",
    "with open('Data/scores_freq.txt', 'w') as fp:\n",
    "    json.dump(scores_freq, fp)\n",
    "with open('Data/scores_sim.txt', 'w') as fp:\n",
    "    json.dump(scores_sim, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5318741.0"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38793.541216463775"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Equalize the contributions of emails sent and text similarity to score\n",
    "k=10\n",
    "factor = sum_freq/sum_sim\n",
    "predictions = {}\n",
    "for id_pred in id_to_pred:\n",
    "    for rec, score_sum in scores_freq[id_pred].iteritems():\n",
    "        scores[id_pred][rec]=scores_freq[id_pred][rec]+factor*scores_sim[id_pred][rec]\n",
    "        \n",
    "    sorted_scores = sorted(scores[id_pred].items(), key=operator.itemgetter(1), reverse=True)\n",
    "    predictions[id_pred]=[elt[0] for elt in sorted_scores[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path_to_results = 'results/'\n",
    "\n",
    "with open(path_to_results + 'predictions_mail_similarity_tf_idf_2.txt', 'wb') as my_file:\n",
    "    my_file.write('mid,recipients' + '\\n')\n",
    "    for id_pred, pred in predictions.iteritems():\n",
    "            my_file.write(str(id_pred) + ',' + ' '.join(pred) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# will contain email ids, predictions for random baseline, and predictions for frequency baseline\n",
    "predictions_per_sender_baseline = {}\n",
    "\n",
    "# number of recipients to predict\n",
    "k = 10\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    name_ids = row.tolist()\n",
    "    sender = name_ids[0]\n",
    "    # get IDs of the emails for which recipient prediction is needed\n",
    "    ids_predict = name_ids[1].split(' ')\n",
    "    ids_predict = [int(my_id) for my_id in ids_predict]\n",
    "    random_preds = []\n",
    "    freq_preds = []\n",
    "    # select k most frequent recipients for the user\n",
    "    k_most = [elt[0] for elt in address_books[sender][:k]]\n",
    "    for id_predict in ids_predict:\n",
    "        # select k users at random\n",
    "        random_preds.append(random.sample(all_users, k))\n",
    "        # for the frequency baseline, the predictions are always the same\n",
    "        freq_preds.append(k_most)\n",
    "    predictions_per_sender_baseline[sender] = [ids_predict, random_preds, freq_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Write predictions in proper format for Kaggle\n",
    "path_to_results = 'results/'\n",
    "\n",
    "with open(path_to_results + 'predictions_random.txt', 'wb') as my_file:\n",
    "    my_file.write('mid,recipients' + '\\n')\n",
    "    for sender, preds in predictions_per_sender_baseline.iteritems():\n",
    "        ids = preds[0]\n",
    "        random_preds = preds[1]\n",
    "        for index, my_preds in enumerate(random_preds):\n",
    "            my_file.write(str(ids[index]) + ',' + ' '.join(my_preds) + '\\n')\n",
    "\n",
    "with open(path_to_results + 'predictions_frequency.txt', 'wb') as my_file:\n",
    "    my_file.write('mid,recipients' + '\\n')\n",
    "    for sender, preds in predictions_per_sender_baseline.iteritems():\n",
    "        ids = preds[0]\n",
    "        freq_preds = preds[2]\n",
    "        for index, my_preds in enumerate(freq_preds):\n",
    "            my_file.write(str(ids[index]) + ',' + ' '.join(my_preds) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
